"""
RAG Tools for Document Retrieval Agents
Handles PDF document search and retrieval using vector databases.
"""

import os
from smolagents import tool
from ..config.agent_config import RAG_CONFIG


@tool
def search_pdf_documents(query: str, pdf_database_path: str, user_notes: str = "") -> str:
    """
    Search through PDF documents using semantic similarity and return results with detailed source citations.
    
    Args:
        query: The search query to find relevant content
        pdf_database_path: Path to the PDF vector database 
        user_notes: Additional context or notes about the search
    
    Returns:
        Retrieved documents content with detailed source citations
    """
    # Enhanced debugging
    print(f"üîç PDF Search Tool called with:")
    print(f"  - Query: {query[:100]}...")
    print(f"  - DB Path: {pdf_database_path}")
    print(f"  - User Notes: {user_notes[:50]}..." if user_notes else "  - No user notes")

    if not pdf_database_path or not isinstance(pdf_database_path, str):
        return "Error: 'pdf_database_path' is missing or invalid."

    # Check for placeholder path
    if pdf_database_path == "path_to_the_pdf_database":
        return """‚ùå Error: Placeholder path detected! 

MANAGER AGENT: You must extract the actual database path from additional_args.

Correct pattern:
1. pdf_context = additional_args.get('pdf_context', {})
2. available_files = pdf_context.get('available_files', [])
3. actual_db_path = available_files[0]['db_path']
4. Use this actual_db_path in the tool call

Do NOT use 'path_to_pdf_database' placeholder!"""

    if not os.path.exists(pdf_database_path):
        return f"Error: Vector DB path not found: {pdf_database_path}"
    
    try:
        from langchain_community.vectorstores import Chroma
        from ..core.embedding import get_embedding_function
        
        # Initialize the Chroma vector store dynamically
        vector_store = Chroma(
            persist_directory=pdf_database_path,
            embedding_function=get_embedding_function(),
            collection_name=RAG_CONFIG["collection_name"]
        )
    except Exception as e:
        return f"Error initializing vector store from {pdf_database_path}: {e}"

    effective_query = query
    if user_notes and isinstance(user_notes, str) and user_notes.strip():
        effective_query = f"{query}\n\nAdditional Context/User Notes:\n{user_notes.strip()}"
        print(f"PDF Search using combined query: {effective_query[:200]}...")
    else:
        print(f"PDF Search using query: {query[:200]}...")

    try:
        # Use similarity_search_with_score to get relevance scores
        docs_with_scores = vector_store.similarity_search_with_score(
            effective_query,
            k=RAG_CONFIG["similarity_search_k"]
        )
    except Exception as e:
        return f"Error during similarity search in {pdf_database_path}: {e}"

    # Format response with detailed source citations
    return _format_search_results_with_citations(docs_with_scores)


def _format_search_results_with_citations(docs_with_scores) -> str:
    """
    Format search results with detailed source citations.
    
    Args:
        docs_with_scores: List of tuples (Document, score) from vector search
        
    Returns:
        Formatted string with documents and source citations
    """
    if not docs_with_scores:
        return "Aucun document pertinent trouv√©."
    
    formatted_results = []
    formatted_results.append("üìÑ Documents trouv√©s avec sources :")
    formatted_results.append("=" * 50)
    
    for i, (doc, score) in enumerate(docs_with_scores):
        # Extract metadata
        metadata = doc.metadata
        filename = metadata.get('filename', 'Fichier inconnu')
        doc_type = metadata.get('type', 'text')
        
        # Format source citation based on type
        source_info = _format_source_citation(metadata, doc_type)
        relevance = f"Pertinence: {(1-score)*100:.1f}%" if score <= 1 else f"Score: {score:.3f}"
        
        formatted_results.append(f"\n===== Document {i+1} =====")
        formatted_results.append(f"üìç {source_info}")
        formatted_results.append(f"üéØ {relevance}")
        formatted_results.append(f"üìã Type: {doc_type}")
        formatted_results.append("-" * 30)
        formatted_results.append(doc.page_content)
        
        # Add extra info for images and tables
        if doc_type == "image" and metadata.get('caption'):
            formatted_results.append(f"üì∏ L√©gende: {metadata['caption']}")
        elif doc_type == "table" and metadata.get('caption'):
            formatted_results.append(f"üìä L√©gende: {metadata['caption']}")
    
    # Add summary footer
    formatted_results.append("\n" + "=" * 50)
    formatted_results.append(f"‚úÖ Total: {len(docs_with_scores)} documents trouv√©s")
    formatted_results.append("üí° Conseil: Citez toujours vos sources en utilisant les informations [Source: ...] fournies ci-dessus")
    
    return "\n".join(formatted_results)


def _format_source_citation(metadata: dict, doc_type: str) -> str:
    """
    Format a source citation based on document type and available metadata.
    
    Args:
        metadata: Document metadata from ChromaDB
        doc_type: Type of document (text, image, table)
        
    Returns:
        Formatted source citation string
    """
    filename = metadata.get('filename', 'Fichier inconnu')
    
    if doc_type == "text":
        # Use actual page number if available, otherwise estimate
        page = metadata.get('page')
        chunk_index = metadata.get('chunk_index', '?')
        chunk_count = metadata.get('chunk_count', '?')
        
        if page is not None:
            chunk_in_page = metadata.get('chunk_in_page', 0)
            total_chunks_in_page = metadata.get('total_chunks_in_page', 1)
            if total_chunks_in_page > 1:
                return f"Source: {filename}, Page {page} (Section {chunk_in_page+1}/{total_chunks_in_page})"
            else:
                return f"Source: {filename}, Page {page}"
        else:
            # Fallback to old estimation method for backwards compatibility
            estimated_page = _estimate_page_from_chunk(chunk_index, chunk_count)
            return f"Source: {filename}, Chunk {chunk_index+1}/{chunk_count} (‚âàPage {estimated_page})"
    
    elif doc_type in ["image", "table"]:
        page = metadata.get('page', '?')
        type_name = "Image" if doc_type == "image" else "Tableau"
        return f"Source: {filename}, Page {page} ({type_name})"
    
    else:
        return f"Source: {filename}"


def _estimate_page_from_chunk(chunk_index: int, chunk_count: int) -> int:
    """
    Estimate page number from chunk index (rough approximation).
    Assumes average chunks per page based on typical document structure.
    
    Args:
        chunk_index: Index of the chunk (0-based)
        chunk_count: Total number of chunks
        
    Returns:
        Estimated page number
    """
    if chunk_count <= 0:
        return 1
    
    # Rough estimate: assume 2-4 chunks per page on average
    # This is a heuristic and could be improved with actual page tracking
    avg_chunks_per_page = max(2, min(4, chunk_count // 10 + 1))
    estimated_page = (chunk_index // avg_chunks_per_page) + 1
    
    return max(1, estimated_page)


@tool  
def search_pdf_with_context(user_query: str, pdf_context_dict: dict = None) -> str:
    """
    Search PDF documents using provided context dictionary.
    
    This tool can be called directly with the PDF context to perform searches.
    
    Args:
        user_query: The user's query about PDF documents
        pdf_context_dict: Dictionary containing PDF context with available_files
        
    Returns:
        Search results from PDF documents or error message
    """
    print(f"üîç search_pdf_with_context called with query: {user_query[:100]}...")
    print(f"üîç PDF context received: {pdf_context_dict}")
    
    if not pdf_context_dict:
        return "No PDF context provided. Please ensure PDF files are loaded or use search_agent for web research instead."
    
    available_files = pdf_context_dict.get("available_files", [])
    print(f"Found {len(available_files)} PDF files available")
    
    if not available_files:
        return "No PDF files are currently indexed. Please upload and index PDF files first."
    
    # Get the database path from the first available file
    first_file = available_files[0]
    db_path = first_file.get("db_path", "")
    user_notes = first_file.get("user_notes", "")
    classification = first_file.get("classification", "General")
    filename = first_file.get("filename", "Unknown PDF")
    
    print(f"Using PDF: {filename}")
    print(f"Database path: {db_path}")
    
    if not db_path or db_path == "path_to_pdf_database":
        return "Error: No valid PDF database path found in context."
    
    # Search the PDF database with the actual path
    search_notes = f"{user_notes} - Classification: {classification}" if user_notes else f"Classification: {classification}"
    result = search_pdf_documents(user_query, db_path, search_notes)
    
    print("PDF search completed successfully")
    return result


@tool
def extract_pdf_context_and_delegate(user_query: str) -> str:
    """
    Deterministic helper that extracts PDF database paths from additional_args 
    and formats the correct RAG agent delegation.
    
    Following smolagents best practice: additional_args become state variables
    that are accessible in the agent's Python code generation.
    
    Args:
        user_query: The user's query about PDF documents
        
    Returns:
        Instructions for the agent to access PDF context from state variables
    """
    # According to smolagents documentation, additional_args are added to agent.state
    # and become accessible as variables in Python code generation
    
    print(f"üîç DEBUG extract_pdf_context_and_delegate:")
    print(f"  - User query: {user_query[:100]}...")
    print("  - Context should be available as state variables: pdf_context, csv_context")
    
    # Return instructions for the agent to access context from its state variables
    instructions = f"""
To answer the query: "{user_query}"

The PDF context is available in the state variable 'pdf_context'.
You can access it in your Python code like this:

```python
# Check if PDF context is available
if 'pdf_context' in locals() and pdf_context:
    # Use the search_pdf_with_context tool with the context
    result = search_pdf_with_context("{user_query}", pdf_context)
    print("PDF search completed")
    final_answer(result)
else:
    final_answer("No PDF context available. Please use search_agent for web research instead.")
```
"""
    
    return instructions


@tool
def get_citation_help() -> str:
    """
    Provides guidance and examples for proper source citation in RAG responses.
    
    Returns:
        Citation guidelines and examples
    """
    return """
üìö Guide des Citations pour RAG - Aleth√©IA

‚úÖ FORMATS DE CITATION RECOMMAND√âS :

1. Pour du texte avec page connue :
   [Source: rapport-annuel.pdf, Page 23]
   [Source: contrat.pdf, Page 5 (Section 2/3)]

2. Pour des images :
   [Source: presentation.pdf, Page 12 (Image)]

3. Pour des tableaux :
   [Source: donnees-financieres.pdf, Page 8 (Tableau)]

4. Pour du texte avec estimation de page :
   [Source: document.pdf, Chunk 15/47 (‚âàPage 8)]

üí° EXEMPLES D'USAGE DANS LES R√âPONSES :

‚ùå Mauvais :
"La soci√©t√© a enregistr√© une croissance de 15%."

‚úÖ Bon :
"Selon le rapport annuel, la soci√©t√© a enregistr√© une croissance de 15% [Source: rapport-annuel.pdf, Page 23]."

‚úÖ Tr√®s bon :
"D'apr√®s les donn√©es financi√®res, la soci√©t√© a enregistr√© une croissance de 15% cette ann√©e [Source: rapport-annuel.pdf, Page 23], ce qui repr√©sente une am√©lioration significative par rapport aux 8% de l'ann√©e pr√©c√©dente [Source: rapport-annuel.pdf, Page 24]."

üéØ BONNES PRATIQUES :
- Toujours citer avant de pr√©senter une information
- Utiliser des phrases d'introduction : "Selon...", "D'apr√®s...", "Le document indique que..."
- Citer chaque source s√©par√©ment quand vous combinez des informations
- √ätre pr√©cis : mentionner la page ET le type de contenu (image/tableau)

üìä AM√âLIORATIONS R√âCENTES :
- ‚úÖ Tracking pr√©cis des pages pour tous les types de contenu
- ‚úÖ Scores de pertinence pour √©valuer la qualit√© des r√©sultats
- ‚úÖ Citations format√©es automatiquement avec m√©tadonn√©es compl√®tes
- ‚úÖ Support des images et tableaux avec localisation pr√©cise
- ‚úÖ Sections multiples par page d√©tect√©es et r√©f√©renc√©es
"""


def get_rag_system_improvements() -> str:
    """
    Returns a summary of recent improvements to the RAG system.
    
    Returns:
        Summary of improvements made to citation and source tracking
    """
    return """
üöÄ AM√âLIORATIONS DU SYST√àME RAG - Aleth√©IA

üìÑ NOUVELLES FONCTIONNALIT√âS :

1. üéØ CITATIONS AUTOMATIQUES :
   - Extraction automatique des m√©tadonn√©es de source
   - Formatage standardis√© des citations
   - Support des scores de pertinence

2. üìç TRACKING PR√âCIS DES PAGES :
   - Pages r√©elles pour tous les chunks de texte
   - Sections multiples par page d√©tect√©es  
   - Localisation pr√©cise des images et tableaux

3. üìä M√âTADONN√âES ENRICHIES :
   - Type de contenu (texte, image, tableau)
   - Position dans le document (chunk X/Y, section Y/Z)
   - Scores de pertinence s√©mantique
   - L√©gendes pour images et tableaux

4. üîç R√âSULTATS AM√âLIOR√âS :
   - Formatage visuel des r√©sultats de recherche
   - Conseils automatiques pour les citations
   - Informations de pertinence pour chaque r√©sultat

üìà B√âN√âFICES :
- ‚úÖ Tra√ßabilit√© compl√®te des informations
- ‚úÖ R√©duction des hallucinations
- ‚úÖ Conformit√© acad√©mique et professionnelle
- ‚úÖ Facilit√© de v√©rification des sources
- ‚úÖ Am√©lioration de la confiance utilisateur

üõ†Ô∏è COMPATIBILIT√â :
- R√©trocompatible avec les anciens documents index√©s
- Estimation de page pour les documents sans tracking
- Support progressif des nouvelles fonctionnalit√©s
"""


@tool
def search_pdf_from_state(user_query: str) -> str:
    """
    Search PDF documents using context that may be available in the agent's environment.
    
    This tool attempts to access PDF context from various sources and provides
    helpful guidance if context is not available.
    
    Args:
        user_query: The user's query about PDF documents
        
    Returns:
        Search results from PDF documents or guidance message
    """
    print(f"üîç search_pdf_from_state called with query: {user_query[:100]}...")
    
    # Check if the query contains context information
    if "Context:" in user_query or "PDF Context Available:" in user_query:
        print("üîç Found context information in query")
        # Extract the actual query part
        if "Query:" in user_query:
            actual_query = user_query.split("Query:")[-1].strip()
            print(f"üîç Extracted query: {actual_query[:100]}...")
        else:
            actual_query = user_query
        
        # For now, return a message indicating delegation is working
        return f"""‚úÖ RAG agent properly called for PDF search!

Query received: "{actual_query}"

This demonstrates that:
1. ‚úÖ Manager agent correctly identified this as a PDF search task
2. ‚úÖ Manager agent successfully delegated to the RAG agent
3. ‚úÖ Context information was passed along

To complete this implementation, the RAG agent would need:
- Access to the actual PDF database paths
- The indexed PDF files to search through
- Proper context passing mechanism from manager to RAG agent

Current status: Delegation pattern working correctly! üéâ"""
    
    # If no context in query, provide guidance
    return f"""RAG agent received query: "{user_query}"

This shows the delegation is working, but to perform actual PDF search, the system needs:

1. PDF files to be uploaded and indexed
2. Database paths to be accessible to the RAG agent
3. Context to be passed from manager agent

For web research instead, please ask the manager to delegate to the search_agent.""" 