"""
RAG Tools for Document Retrieval Agents - Version Simple avec Affichage Direct
Affiche automatiquement les sources trouv√©es lors de la recherche vectorielle.
"""

import os
import json
import logging
import re
import time
import streamlit as st
from smolagents import tool
from ..config.agent_config import RAG_CONFIG

# Configure logging for RAG tools debug - disable HTTP/API logs
logging.basicConfig(level=logging.WARNING)  # Set global level to WARNING
logger = logging.getLogger(__name__)

# Disable verbose HTTP/API logs
logging.getLogger("openai._base_client").setLevel(logging.WARNING)
logging.getLogger("httpcore.http11").setLevel(logging.WARNING)
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("urllib3.connectionpool").setLevel(logging.WARNING)

# Cache temporaire global pour les sources RAG
_temp_rag_sources_cache = []

@tool
def rag_search_simple(query: str) -> str:
    """
    Search PDF documents and return answer with citations.
    AFFICHE AUTOMATIQUEMENT les sources trouv√©es avec scores de pertinence.
    
    Args:
        query: Search terms for PDF documents.
    
    Returns:
        Answer with citations [SOURCE-1], [SOURCE-2], etc.
    """
    
    print(f"üìö RAG SEARCH: Starting search for: '{query}'")
    
    if not query or not isinstance(query, str):
        return "‚ùå Query must be a non-empty string"
    
    try:
        # Try to import session state (will fail outside Streamlit)
        try:
            import streamlit as st
            in_streamlit = True
        except:
            in_streamlit = False
            
        # Load session data
        session_file = "data/session_persistence/persistent_session_state.json"
        print(f"üìö RAG SEARCH: Checking session file: {session_file}")
        
        if not os.path.exists(session_file):
            print("‚ùå RAG SEARCH: No session file found")
            return "‚ùå Aucun document PDF n'est disponible pour la recherche. Veuillez d'abord t√©l√©charger des documents PDF."
        
        print(f"üìö RAG SEARCH: Loading session data...")
        with open(session_file, 'r', encoding='utf-8') as f:
            processed_files = json.load(f)
        
        print(f"üìö RAG SEARCH: Loaded {len(processed_files)} files from session")
        
        # Find indexed PDFs
        available_pdfs = []
        for fid, details in processed_files.items():
            if details.get('type') == 'pdf' and details.get('indexed') and details.get('db_path'):
                available_pdfs.append({
                    'file_id': fid,
                    'filename': details.get('filename', 'Unknown PDF'),
                    'db_path': details.get('db_path'),
                })
                print(f"üìÑ RAG SEARCH: Found indexed PDF - {details.get('filename')} at {details.get('db_path')}")
        
        if not available_pdfs:
            print("‚ùå RAG SEARCH: No indexed PDFs found")
            return "‚ùå Aucun document PDF index√© n'est disponible pour la recherche. Veuillez d'abord indexer des documents PDF."
        
        # Use first available PDF
        first_pdf = available_pdfs[0]
        db_path = first_pdf['db_path']
        filename = first_pdf['filename']
        
        print(f"üìö RAG SEARCH: Using PDF '{filename}' with database: {db_path}")
        
        if not os.path.exists(db_path):
            print(f"‚ùå RAG SEARCH: Database path does not exist: {db_path}")
            return f"‚ùå Base de donn√©es vectorielle introuvable: {db_path}"
        
        # Initialize vector store
        from langchain_community.vectorstores import Chroma
        from ..core.embedding import get_embedding_function
        
        print(f"üìö RAG SEARCH: Initializing vector store...")
        embedding_function = get_embedding_function()
        vector_store = Chroma(
            persist_directory=db_path,
            embedding_function=embedding_function,
            collection_name=RAG_CONFIG["collection_name"]
        )
        
        # Check if we have documents
        try:
            doc_count = vector_store._collection.count()
            if doc_count == 0:
                print("‚ùå RAG SEARCH: No documents found in vector store")
                return "‚ùå Aucun document trouv√© dans la base vectorielle."
        except:
            print("‚ùå RAG SEARCH: Could not access vector store collection")
            return "‚ùå Erreur d'acc√®s √† la base de donn√©es vectorielle."
        
        print(f"üìö RAG SEARCH: Found {doc_count} documents in vector store")
        
        # Perform search
        results = vector_store.similarity_search_with_score(query, k=5)
        print(f"üìö RAG SEARCH: Found {len(results)} relevant passages")
        
        if not results:
            print("‚ùå RAG SEARCH: No relevant passages found")
            return f"‚ùå Aucun passage pertinent trouv√© pour la requ√™te: '{query}'"
        
        # AFFICHAGE DIRECT D√âSACTIV√â - Les sources seront affich√©es apr√®s la r√©ponse
        print("üé® RAG SEARCH: Sources seront affich√©es via le syst√®me de cache apr√®s la r√©ponse")
        
        # Format results for response
        response_parts = []
        sources_data = []
        
        for i, (doc, score) in enumerate(results, 1):
            content = doc.page_content.strip()
            metadata = doc.metadata or {}
            page = metadata.get('page', '?')
            source = metadata.get('source') or metadata.get('filename', filename)
            
            # LOGGING: Print detailed info for the LLM agent
            print(f"üìÑ SOURCE {i}: {source}, page {page} (score: {score:.3f})")
            print(f"üìù CONTENT {i}: {content[:200]}...")
            
            # Add to response with citation
            response_parts.append(f"‚Ä¢ {content} [SOURCE-{i}]")
            
            # Store for potential future use
            sources_data.append({
                "content": content,
                "metadata": {
                    "source": source,
                    "page": page,
                    "relevance_score": float(1 - score),  # Convert distance to relevance
                    "citation_index": i
                }
            })
        
        # Build final response with clear page references
        response = f"R√âPONSE DOCUMENT√âE bas√©e sur {len(sources_data)} sources dans le document '{filename}':\n\n"
        
        # Format each passage with clear page references
        formatted_parts = []
        for i, (doc, score) in enumerate(results, 1):
            content = doc.page_content.strip()
            metadata = doc.metadata or {}
            page = metadata.get('page', '?')
            
            # Format with clear page indication
            formatted_parts.append(f"üìÑ **Page {page}**: {content} [SOURCE-{i}]")
        
        response += "\n\n".join(formatted_parts)
        response += f"\n\nüìö **R√âF√âRENCES COMPL√àTES:**\n"
        for i, source_data in enumerate(sources_data, 1):
            metadata = source_data["metadata"]
            response += f"[SOURCE-{i}] {metadata['source']}, page {metadata['page']} (pertinence: {metadata['relevance_score']:.0%})\n"
        
        print(f"‚úÖ RAG SEARCH: Successfully generated response with {len(sources_data)} citations")
        print(f"‚úÖ RAG SEARCH: Sources displayed directly in UI")
        
        # Sauvegarder les sources pour affichage automatique
        _save_rag_sources_to_temp_cache(results, query, filename)
        
        return response
        
    except Exception as e:
        error_msg = f"‚ùå Erreur lors de la recherche RAG: {str(e)}"
        print(f"‚ùå RAG SEARCH ERROR: {error_msg}")
        return error_msg


def _save_rag_sources_to_temp_cache(sources_data: list, query: str, filename: str) -> None:
    """
    Sauvegarde les sources RAG dans un cache temporaire global.
    """
    global _temp_rag_sources_cache
    
    try:
        if not sources_data:
            print("‚ö†Ô∏è Aucune source √† sauvegarder")
            return
            
        print(f"üîÑ Tentative de sauvegarde de {len(sources_data)} sources...")
        
        # Pr√©parer les donn√©es pour l'affichage
        formatted_sources = {
            "query": query,
            "filename": filename,
            "timestamp": time.time(),
            "results": []
        }
        
        for i, (doc, score) in enumerate(sources_data, 1):
            content = doc.page_content.strip()
            metadata = doc.metadata or {}
            page = metadata.get('page', '?')
            source = metadata.get('source') or metadata.get('filename', filename)
            relevance = float(1 - score) * 100  # Convert distance to percentage
            
            formatted_sources["results"].append({
                "content": content,
                "metadata": {
                    "source": source,
                    "page": str(page),
                    "relevance_score": relevance,
                    "citation_index": i
                }
            })
        
        # Sauvegarder dans le cache temporaire global
        _temp_rag_sources_cache.append(formatted_sources)
        
        # Garder seulement les 5 derni√®res recherches
        if len(_temp_rag_sources_cache) > 5:
            _temp_rag_sources_cache = _temp_rag_sources_cache[-5:]
        
        print(f"‚úÖ Sources sauvegard√©es dans cache temporaire: {len(formatted_sources['results'])} sources pour '{query}'")
        
        # Essayer aussi de sauvegarder dans le session state si possible
        try:
            if 'st' in globals() and hasattr(st, 'session_state'):
                if 'rag_sources_cache' not in st.session_state:
                    st.session_state.rag_sources_cache = []
                st.session_state.rag_sources_cache.append(formatted_sources)
                if len(st.session_state.rag_sources_cache) > 5:
                    st.session_state.rag_sources_cache = st.session_state.rag_sources_cache[-5:]
                print("‚úÖ Sources aussi sauvegard√©es dans session state")
        except Exception as e:
            print(f"‚ö†Ô∏è Session state indisponible: {e}")
        
    except Exception as e:
        print(f"‚ùå Erreur lors de la sauvegarde des sources: {e}")
        import traceback
        traceback.print_exc()


def get_latest_rag_sources():
    """
    R√©cup√®re les derni√®res sources RAG sauvegard√©es (session state ou cache temporaire).
    """
    try:
        # Essayer d'abord le session state
        if 'st' in globals() and hasattr(st, 'session_state') and 'rag_sources_cache' in st.session_state:
            if st.session_state.rag_sources_cache:
                print("üìö Sources r√©cup√©r√©es depuis session state")
                return st.session_state.rag_sources_cache[-1]
    except:
        pass
    
    # Fallback vers le cache temporaire global
    try:
        global _temp_rag_sources_cache
        if _temp_rag_sources_cache:
            print("üìö Sources r√©cup√©r√©es depuis cache temporaire")
            return _temp_rag_sources_cache[-1]
    except:
        pass
    
    print("‚ö†Ô∏è Aucune source trouv√©e dans les caches")
    return None


def clear_rag_sources_cache():
    """
    Vide les caches des sources RAG.
    """
    global _temp_rag_sources_cache
    
    try:
        # Vider le cache temporaire
        _temp_rag_sources_cache = []
        
        # Vider le session state si possible
        if 'st' in globals() and hasattr(st, 'session_state') and 'rag_sources_cache' in st.session_state:
            st.session_state.rag_sources_cache = []
        
        print("üßπ Caches des sources RAG vid√©s")
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur lors du nettoyage des caches: {e}")
