import streamlit as st
import os
import shutil
import uuid
import tempfile
from smolagents import CodeAgent, ToolCallingAgent, DuckDuckGoSearchTool, VisitWebpageTool, OpenAIServerModel
from managed_agent.csv_analyzer_tool import CSVAnalyzerTool
from utils.pipeline_indexation.csv_processor import CSVProcessor

def route_request(query, csv_args, search_agent, data_analyst):
    """
    Fonction de routage qui d√©l√®gue la requ√™te √† l'agent sp√©cialis√©.
    Si csv_args est fourni (indiquant la pr√©sence d'un fichier CSV), la requ√™te est d√©l√©gu√©e √† data_analyst.
    Sinon, la requ√™te est envoy√©e √† search_agent.
    """
    if csv_args is not None:
        # D√©finir le prompt selon la pr√©sence ou non des additional_notes
        additional_notes = csv_args.get('additional_notes', '').strip()
        
        # Message de base indiquant l'expertise en data-analysis
        expertise_message = (
            "Vous √™tes un expert en data-analysis. "
            "Votre t√¢che est d'analyser le fichier CSV fourni afin de r√©pondre √† la question pos√©e. "
        )
        
        # Construire le prompt en incluant les notes additionnelles
        prompt = (
            f"{expertise_message}\n"
            f"Analyse du fichier CSV: {query}\n\n"
            f"Notes additionnelles et contexte: {additional_notes}"
        )

        # Pr√©parer les arguments pour l'outil csv_analyzer.
        csv_analyzer_args = {
            "source_file": csv_args["source_file"],
            "separator": csv_args["separator"],
            "figures_dir": csv_args["figures_dir"],
            "chunk_size": csv_args["chunk_size"]
        }
        
        return data_analyst.run(prompt, additional_args={"csv_analyzer": csv_analyzer_args})
    else:
        # D√©l√©gation √† l'agent de recherche pour traiter la requ√™te g√©n√©rale.
        return search_agent.run(query)

def cleanup_resources(figures_dir):
    """
    Nettoie les ressources utilis√©es par les agents.
    
    Args:
        figures_dir: Chemin vers le dossier contenant les figures g√©n√©r√©es.
    """
    if os.path.exists(figures_dir):
        try:
            shutil.rmtree(figures_dir)
            os.makedirs(figures_dir, exist_ok=True)
        except Exception as e:
            st.warning(f"Impossible de nettoyer le dossier des figures: {e}")
    else:
        os.makedirs(figures_dir, exist_ok=True)

def main():
    st.title("Agent Web avec Streamlit")
    st.write("Entrez votre cl√© API OpenAI et votre requ√™te pour interroger l'agent.")

    # Initialisation de la session si n√©cessaire.
    if 'session_id' not in st.session_state:
        st.session_state.session_id = str(uuid.uuid4())
    
    # Dossier sp√©cifique pour les figures de cette session.
    figures_dir = os.path.join('./figures', st.session_state.session_id)
    
    # R√©cup√©ration de la cl√© API depuis les variables d'environnement.
    api_key_from_env = os.environ.get("OPENAI_API_KEY")
    
    # Saisie de la cl√© API seulement si elle n'est pas d√©j√† d√©finie.
    if not api_key_from_env:
        api_key = st.text_input("Cl√© API OpenAI", type="password")
    else:
        st.success("Cl√© API OpenAI trouv√©e dans les variables d'environnement")
        api_key = api_key_from_env
    
    # Upload d'un fichier CSV (optionnel).
    uploaded_file = st.file_uploader("D√©poser un fichier CSV (optionnel)", type=['csv'])
    
    # Option pour limiter l'utilisation de la m√©moire.
    use_memory_limit = st.checkbox("Limiter l'utilisation de la m√©moire (recommand√© pour les grands fichiers)", value=True)
    chunk_size = 100000 if use_memory_limit else None
    
    # Permettre √† l'utilisateur d'ajouter ses propres notes sur le fichier
    user_notes = ""
    if uploaded_file:
        user_notes = st.text_area("Notes additionnelles sur le fichier", 
                                  placeholder="Ajoutez ici vos observations, questions sp√©cifiques ou contexte sur le fichier CSV...",
                                  height=150)
    
    # Saisie de la requ√™te utilisateur.
    user_query = st.text_input("Requ√™te √† envoyer √† l'agent")
    
    if st.button("Ex√©cuter"):
        # V√©rification des entr√©es.
        if not api_key:
            st.error("Veuillez entrer une cl√© API valide.")
            return
        if not user_query:
            st.error("Veuillez entrer une requ√™te.")
            return
        
        # Nettoyer les ressources pr√©c√©dentes.
        cleanup_resources(figures_dir)
        
        # D√©finition de la cl√© API dans l'environnement.
        os.environ["OPENAI_API_KEY"] = api_key
        
        # Cr√©ation du mod√®le OpenAIServerModel.
        model = OpenAIServerModel(
            model_id="gpt-4o",
            api_base="https://api.openai.com/v1",
            api_key=api_key,
        )
        
        # Cr√©ation de l'agent de recherche (search_agent).
        search_agent = ToolCallingAgent(
            tools=[DuckDuckGoSearchTool(), VisitWebpageTool()],
            model=model,
            name="search_agent",
            description="Effectue des recherches sur le web en utilisant DuckDuckGo et visite des pages web."
        )
        
        # Cr√©ation de l'agent d'analyse des donn√©es (data_analyst).
        authorized_imports = [
            "pandas", "numpy", "matplotlib", "matplotlib.pyplot", 
            "seaborn", "io", "base64", "tempfile", "os"
        ]
        data_analyst = CodeAgent(
            tools=[],
            model=model,
            additional_authorized_imports=authorized_imports,
            name="data_analyst",
            description="Analyse les fichiers CSV et g√©n√®re des visualisations √† partir des donn√©es."
        )
        
        # Liste des agents g√©r√©s.
        managed_agents = [search_agent, data_analyst]
        
        # Pr√©paration des param√®tres li√©s au fichier CSV s'il y a lieu.
        csv_args = None
        if uploaded_file is not None:
            try:
                # Cr√©er un r√©pertoire pour stocker les fichiers CSV
                csv_dir = os.path.join("data", "csv_files")
                os.makedirs(csv_dir, exist_ok=True)
                
                # G√©n√©rer un nom de fichier unique bas√© sur le nom original
                original_filename = uploaded_file.name
                base_name = os.path.splitext(original_filename)[0]
                unique_filename = f"{base_name}_{str(uuid.uuid4())[:8]}.csv"
                csv_file_path = os.path.join(csv_dir, unique_filename)
                
                # Lire et sauvegarder le contenu du fichier
                file_content = uploaded_file.getvalue().decode("utf-8", errors="replace")
                with open(csv_file_path, "w", encoding="utf-8") as f:
                    f.write(file_content)
                
                # Utiliser CSVProcessor pour valider et analyser le fichier
                csv_processor = CSVProcessor()
                is_valid, validation_message = csv_processor.validate_csv(csv_file_path, auto_detect=True)
                
                if not is_valid:
                    st.error(f"Le fichier CSV n'est pas valide: {validation_message}")
                    return
                
                # R√©cup√©rer les informations d√©tect√©es
                separator = csv_processor.separator
                encoding = csv_processor.encoding
                
                # Analyse basique pour obtenir des informations sur le fichier
                basic_analysis = csv_processor.analyze_csv(csv_file_path, auto_detect=True)
                columns = basic_analysis.get("colonnes", [])
                rows = basic_analysis.get("nombre_lignes", 0)
                
                # Estimer la taille du fichier pour recommandations de m√©moire
                file_size_mb = len(file_content) / (1024 * 1024)
                memory_warning = ""
                if file_size_mb > 10 and not use_memory_limit:
                    memory_warning = "‚ö†Ô∏è Le fichier est relativement volumineux. L'option de limitation de m√©moire est recommand√©e."
                
                # Pr√©parer les notes pour le data_analyst
                data_analyst_notes = f"""
# Guide d'analyse de donn√©es
- Fichier: {original_filename}
- Chemin: {csv_file_path}
- S√©parateur: '{separator}'
- Encodage: {encoding}
- Dossier pour figures: '{figures_dir}'
- Taille du fichier: {file_size_mb:.2f} MB
- Nombre de lignes: {rows}
- Nombre de colonnes: {len(columns)}

# Colonnes d√©tect√©es:
{', '.join(columns)}

# Notes de l'utilisateur:
{user_notes if user_notes else "Aucune note sp√©cifique fournie par l'utilisateur."}

# √âtapes recommand√©es:
1. Validation du fichier CSV via csv_analyzer (d√©j√† effectu√©e: {validation_message})
2. Exploration des donn√©es avec df.info(), df.describe() et v√©rification des valeurs manquantes
3. Cr√©ation de visualisations adapt√©es au type de donn√©es
4. Enregistrer toutes les figures dans le dossier '{figures_dir}'
                """
                
                csv_args = {
                    "source_file": csv_file_path, 
                    "separator": separator, 
                    "additional_notes": data_analyst_notes,
                    "figures_dir": figures_dir,
                    "chunk_size": chunk_size
                }
                
                info_message = f"Fichier CSV valid√© avec s√©parateur '{separator}' et encodage '{encoding}'. L'agent Data Analyst sera utilis√©."
                if memory_warning:
                    info_message += f" {memory_warning}"
                st.info(info_message)
            
            except Exception as e:
                st.error(f"Erreur lors du traitement du fichier CSV: {str(e)}")
                return
        else:
            st.info("Aucun fichier CSV d√©tect√©. L'agent de recherche sera utilis√©.")
        
        # Utilisation de la fonction de routage pour d√©l√©guer la requ√™te.
        with st.spinner("L'agent traite votre requ√™te..."):
            try:
                result = route_request(user_query, csv_args, search_agent, data_analyst)
            except Exception as e:
                st.error(f"Erreur lors du traitement de la requ√™te: {str(e)}")
                return
        
        st.subheader("R√©sultat de l'agent")
        st.markdown(result, unsafe_allow_html=True)
        
        # Afficher les figures g√©n√©r√©es dans le dossier des figures, si pr√©sentes.
        if os.path.exists(figures_dir) and os.listdir(figures_dir):
            st.subheader("Figures g√©n√©r√©es")
            for fig_file in os.listdir(figures_dir):
                if fig_file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    st.image(os.path.join(figures_dir, fig_file), caption=fig_file)
        
        # Conseil compl√©mentaire pour l'analyse de donn√©es.
        if csv_args is not None:
            st.info("üí° Conseil: Vous pouvez demander √† l'agent d'effectuer des analyses plus sp√©cifiques, comme des corr√©lations ou des statistiques d√©taill√©es sur vos donn√©es CSV.")

if __name__ == "__main__":
    main()